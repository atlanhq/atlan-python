# Auto-generated by PythonMsgspecRenderer.pkl - DO NOT EDIT
# SPDX-License-Identifier: Apache-2.0
# Copyright 2024 Atlan Pte. Ltd.

"""
DatabricksExternalLocationPath asset model with flattened inheritance.

This module provides:
- DatabricksExternalLocationPath: Flat asset class (easy to use)
- DatabricksExternalLocationPathAttributes: Nested attributes struct (extends AssetAttributes)
- DatabricksExternalLocationPathNested: Nested API format struct
"""

from __future__ import annotations

from typing import Union

from msgspec import UNSET, UnsetType

from pyatlan_v9.conversion_utils import categorize_relationships, merge_relationships
from pyatlan_v9.serde import Serde, get_serde
from pyatlan_v9.transform import register_asset

from .asset import Asset, AssetAttributes, AssetNested, AssetRelationshipAttributes
from .databricks_related import RelatedDatabricksExternalLocation

# =============================================================================
# FLAT ASSET CLASS
# =============================================================================


@register_asset
class DatabricksExternalLocationPath(Asset):
    """
    Represents a path within a Databricks External Location, providing access to specific data files or directories in external storage.
    """

    # Override type_name with DatabricksExternalLocationPath-specific default
    type_name: Union[str, UnsetType] = "DatabricksExternalLocationPath"

    databricks_path: Union[str, None, UnsetType] = UNSET
    """Path of data at the external location."""

    databricks_parent_qualified_name: Union[str, None, UnsetType] = UNSET
    """Qualified name of the parent external location."""

    databricks_parent_name: Union[str, None, UnsetType] = UNSET
    """Name of the parent external location."""

    query_count: Union[int, None, UnsetType] = UNSET
    """Number of times this asset has been queried."""

    query_user_count: Union[int, None, UnsetType] = UNSET
    """Number of unique users who have queried this asset."""

    query_user_map: Union[dict[str, int], None, UnsetType] = UNSET
    """Map of unique users who have queried this asset to the number of times they have queried it."""

    query_count_updated_at: Union[int, None, UnsetType] = UNSET
    """Time (epoch) at which the query count was last updated, in milliseconds."""

    database_name: Union[str, None, UnsetType] = UNSET
    """Simple name of the database in which this SQL asset exists, or empty if it does not exist within a database."""

    database_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the database in which this SQL asset exists, or empty if it does not exist within a database."""

    schema_name: Union[str, None, UnsetType] = UNSET
    """Simple name of the schema in which this SQL asset exists, or empty if it does not exist within a schema."""

    schema_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the schema in which this SQL asset exists, or empty if it does not exist within a schema."""

    table_name: Union[str, None, UnsetType] = UNSET
    """Simple name of the table in which this SQL asset exists, or empty if it does not exist within a table."""

    table_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the table in which this SQL asset exists, or empty if it does not exist within a table."""

    view_name: Union[str, None, UnsetType] = UNSET
    """Simple name of the view in which this SQL asset exists, or empty if it does not exist within a view."""

    view_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the view in which this SQL asset exists, or empty if it does not exist within a view."""

    calculation_view_name: Union[str, None, UnsetType] = UNSET
    """Simple name of the calculation view in which this SQL asset exists, or empty if it does not exist within a calculation view."""

    calculation_view_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the calculation view in which this SQL asset exists, or empty if it does not exist within a calculation view."""

    is_profiled: Union[bool, None, UnsetType] = UNSET
    """Whether this asset has been profiled (true) or not (false)."""

    last_profiled_at: Union[int, None, UnsetType] = UNSET
    """Time (epoch) at which this asset was last profiled, in milliseconds."""

    sql_ai_model_context_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the context in which the model versions exist, or empty if it does not exist within an AI model context."""

    sql_is_secure: Union[bool, None, UnsetType] = UNSET
    """Whether this asset is secure (true) or not (false)."""

    databricks_external_location: Union[
        RelatedDatabricksExternalLocation, None, UnsetType
    ] = UNSET
    """External location that contains the paths."""

    # =========================================================================
    # Optimized Serialization Methods (override Asset base class)
    # =========================================================================

    def to_json(self, nested: bool = True, serde: Serde | None = None) -> str:
        """
        Convert to JSON string using optimized nested struct serialization.

        Args:
            nested: If True (default), use nested API format. If False, use flat format.
            serde: Optional Serde instance for encoder reuse. Uses shared singleton if None.

        Returns:
            JSON string representation
        """
        if serde is None:
            serde = get_serde()
        if nested:
            return _databricks_external_location_path_to_nested_bytes(
                self, serde
            ).decode("utf-8")
        else:
            return serde.encode(self).decode("utf-8")

    @staticmethod
    def from_json(
        json_data: Union[str, bytes], serde: Serde | None = None
    ) -> "DatabricksExternalLocationPath":
        """
        Create from JSON string or bytes using optimized nested struct deserialization.

        Args:
            json_data: JSON string or bytes to deserialize
            serde: Optional Serde instance for decoder reuse. Uses shared singleton if None.

        Returns:
            DatabricksExternalLocationPath instance
        """
        if isinstance(json_data, str):
            json_data = json_data.encode("utf-8")
        if serde is None:
            serde = get_serde()
        return _databricks_external_location_path_from_nested_bytes(json_data, serde)


# =============================================================================
# NESTED FORMAT CLASSES
# =============================================================================


class DatabricksExternalLocationPathAttributes(AssetAttributes):
    """DatabricksExternalLocationPath-specific attributes for nested API format."""

    databricks_path: Union[str, None, UnsetType] = UNSET
    """Path of data at the external location."""

    databricks_parent_qualified_name: Union[str, None, UnsetType] = UNSET
    """Qualified name of the parent external location."""

    databricks_parent_name: Union[str, None, UnsetType] = UNSET
    """Name of the parent external location."""

    query_count: Union[int, None, UnsetType] = UNSET
    """Number of times this asset has been queried."""

    query_user_count: Union[int, None, UnsetType] = UNSET
    """Number of unique users who have queried this asset."""

    query_user_map: Union[dict[str, int], None, UnsetType] = UNSET
    """Map of unique users who have queried this asset to the number of times they have queried it."""

    query_count_updated_at: Union[int, None, UnsetType] = UNSET
    """Time (epoch) at which the query count was last updated, in milliseconds."""

    database_name: Union[str, None, UnsetType] = UNSET
    """Simple name of the database in which this SQL asset exists, or empty if it does not exist within a database."""

    database_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the database in which this SQL asset exists, or empty if it does not exist within a database."""

    schema_name: Union[str, None, UnsetType] = UNSET
    """Simple name of the schema in which this SQL asset exists, or empty if it does not exist within a schema."""

    schema_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the schema in which this SQL asset exists, or empty if it does not exist within a schema."""

    table_name: Union[str, None, UnsetType] = UNSET
    """Simple name of the table in which this SQL asset exists, or empty if it does not exist within a table."""

    table_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the table in which this SQL asset exists, or empty if it does not exist within a table."""

    view_name: Union[str, None, UnsetType] = UNSET
    """Simple name of the view in which this SQL asset exists, or empty if it does not exist within a view."""

    view_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the view in which this SQL asset exists, or empty if it does not exist within a view."""

    calculation_view_name: Union[str, None, UnsetType] = UNSET
    """Simple name of the calculation view in which this SQL asset exists, or empty if it does not exist within a calculation view."""

    calculation_view_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the calculation view in which this SQL asset exists, or empty if it does not exist within a calculation view."""

    is_profiled: Union[bool, None, UnsetType] = UNSET
    """Whether this asset has been profiled (true) or not (false)."""

    last_profiled_at: Union[int, None, UnsetType] = UNSET
    """Time (epoch) at which this asset was last profiled, in milliseconds."""

    sql_ai_model_context_qualified_name: Union[str, None, UnsetType] = UNSET
    """Unique name of the context in which the model versions exist, or empty if it does not exist within an AI model context."""

    sql_is_secure: Union[bool, None, UnsetType] = UNSET
    """Whether this asset is secure (true) or not (false)."""


class DatabricksExternalLocationPathRelationshipAttributes(AssetRelationshipAttributes):
    """DatabricksExternalLocationPath-specific relationship attributes for nested API format."""

    databricks_external_location: Union[
        RelatedDatabricksExternalLocation, None, UnsetType
    ] = UNSET
    """External location that contains the paths."""


class DatabricksExternalLocationPathNested(AssetNested):
    """DatabricksExternalLocationPath in nested API format for high-performance serialization."""

    attributes: Union[DatabricksExternalLocationPathAttributes, UnsetType] = UNSET
    relationship_attributes: Union[
        DatabricksExternalLocationPathRelationshipAttributes, UnsetType
    ] = UNSET
    append_relationship_attributes: Union[
        DatabricksExternalLocationPathRelationshipAttributes, UnsetType
    ] = UNSET
    remove_relationship_attributes: Union[
        DatabricksExternalLocationPathRelationshipAttributes, UnsetType
    ] = UNSET


# =============================================================================
# CONVERSION FUNCTIONS
# =============================================================================


def _databricks_external_location_path_to_nested(
    databricks_external_location_path: DatabricksExternalLocationPath,
) -> DatabricksExternalLocationPathNested:
    """Convert flat DatabricksExternalLocationPath to nested format."""
    attrs = DatabricksExternalLocationPathAttributes(
        databricks_path=databricks_external_location_path.databricks_path,
        databricks_parent_qualified_name=databricks_external_location_path.databricks_parent_qualified_name,
        databricks_parent_name=databricks_external_location_path.databricks_parent_name,
        query_count=databricks_external_location_path.query_count,
        query_user_count=databricks_external_location_path.query_user_count,
        query_user_map=databricks_external_location_path.query_user_map,
        query_count_updated_at=databricks_external_location_path.query_count_updated_at,
        database_name=databricks_external_location_path.database_name,
        database_qualified_name=databricks_external_location_path.database_qualified_name,
        schema_name=databricks_external_location_path.schema_name,
        schema_qualified_name=databricks_external_location_path.schema_qualified_name,
        table_name=databricks_external_location_path.table_name,
        table_qualified_name=databricks_external_location_path.table_qualified_name,
        view_name=databricks_external_location_path.view_name,
        view_qualified_name=databricks_external_location_path.view_qualified_name,
        calculation_view_name=databricks_external_location_path.calculation_view_name,
        calculation_view_qualified_name=databricks_external_location_path.calculation_view_qualified_name,
        is_profiled=databricks_external_location_path.is_profiled,
        last_profiled_at=databricks_external_location_path.last_profiled_at,
        sql_ai_model_context_qualified_name=databricks_external_location_path.sql_ai_model_context_qualified_name,
        sql_is_secure=databricks_external_location_path.sql_is_secure,
    )
    # Categorize relationships by save semantic (REPLACE, APPEND, REMOVE)
    rel_fields: list[str] = ["databricks_external_location"]
    replace_rels, append_rels, remove_rels = categorize_relationships(
        databricks_external_location_path,
        rel_fields,
        DatabricksExternalLocationPathRelationshipAttributes,
    )
    return DatabricksExternalLocationPathNested(
        guid=databricks_external_location_path.guid,
        type_name=databricks_external_location_path.type_name,
        status=databricks_external_location_path.status,
        version=databricks_external_location_path.version,
        create_time=databricks_external_location_path.create_time,
        update_time=databricks_external_location_path.update_time,
        created_by=databricks_external_location_path.created_by,
        updated_by=databricks_external_location_path.updated_by,
        classifications=databricks_external_location_path.classifications,
        classification_names=databricks_external_location_path.classification_names,
        meanings=databricks_external_location_path.meanings,
        labels=databricks_external_location_path.labels,
        business_attributes=databricks_external_location_path.business_attributes,
        custom_attributes=databricks_external_location_path.custom_attributes,
        pending_tasks=databricks_external_location_path.pending_tasks,
        proxy=databricks_external_location_path.proxy,
        is_incomplete=databricks_external_location_path.is_incomplete,
        provenance_type=databricks_external_location_path.provenance_type,
        home_id=databricks_external_location_path.home_id,
        attributes=attrs,
        relationship_attributes=replace_rels,
        append_relationship_attributes=append_rels,
        remove_relationship_attributes=remove_rels,
    )


def _databricks_external_location_path_from_nested(
    nested: DatabricksExternalLocationPathNested,
) -> DatabricksExternalLocationPath:
    """Convert nested format to flat DatabricksExternalLocationPath."""
    attrs = (
        nested.attributes
        if nested.attributes is not UNSET
        else DatabricksExternalLocationPathAttributes()
    )
    # Merge relationships from all three buckets
    rel_fields: list[str] = ["databricks_external_location"]
    merged_rels = merge_relationships(
        nested.relationship_attributes,
        nested.append_relationship_attributes,
        nested.remove_relationship_attributes,
        rel_fields,
        DatabricksExternalLocationPathRelationshipAttributes,
    )
    return DatabricksExternalLocationPath(
        guid=nested.guid,
        type_name=nested.type_name,
        status=nested.status,
        version=nested.version,
        create_time=nested.create_time,
        update_time=nested.update_time,
        created_by=nested.created_by,
        updated_by=nested.updated_by,
        classifications=nested.classifications,
        classification_names=nested.classification_names,
        meanings=nested.meanings,
        labels=nested.labels,
        business_attributes=nested.business_attributes,
        custom_attributes=nested.custom_attributes,
        pending_tasks=nested.pending_tasks,
        proxy=nested.proxy,
        is_incomplete=nested.is_incomplete,
        provenance_type=nested.provenance_type,
        home_id=nested.home_id,
        databricks_path=attrs.databricks_path,
        databricks_parent_qualified_name=attrs.databricks_parent_qualified_name,
        databricks_parent_name=attrs.databricks_parent_name,
        query_count=attrs.query_count,
        query_user_count=attrs.query_user_count,
        query_user_map=attrs.query_user_map,
        query_count_updated_at=attrs.query_count_updated_at,
        database_name=attrs.database_name,
        database_qualified_name=attrs.database_qualified_name,
        schema_name=attrs.schema_name,
        schema_qualified_name=attrs.schema_qualified_name,
        table_name=attrs.table_name,
        table_qualified_name=attrs.table_qualified_name,
        view_name=attrs.view_name,
        view_qualified_name=attrs.view_qualified_name,
        calculation_view_name=attrs.calculation_view_name,
        calculation_view_qualified_name=attrs.calculation_view_qualified_name,
        is_profiled=attrs.is_profiled,
        last_profiled_at=attrs.last_profiled_at,
        sql_ai_model_context_qualified_name=attrs.sql_ai_model_context_qualified_name,
        sql_is_secure=attrs.sql_is_secure,
        # Merged relationship attributes
        **merged_rels,
    )


def _databricks_external_location_path_to_nested_bytes(
    databricks_external_location_path: DatabricksExternalLocationPath, serde: Serde
) -> bytes:
    """Convert flat DatabricksExternalLocationPath to nested JSON bytes."""
    return serde.encode(
        _databricks_external_location_path_to_nested(databricks_external_location_path)
    )


def _databricks_external_location_path_from_nested_bytes(
    data: bytes, serde: Serde
) -> DatabricksExternalLocationPath:
    """Convert nested JSON bytes to flat DatabricksExternalLocationPath."""
    nested = serde.decode(data, DatabricksExternalLocationPathNested)
    return _databricks_external_location_path_from_nested(nested)
